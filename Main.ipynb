{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>LEARNING FROM NETWORK PROJECT</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 1: Network Generation</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages and create an instance of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NetworkManager import NetworkManager\n",
    "NM = NetworkManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the edges list using the <i>featGenerator</i> method  (may take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM.featGenerator(\"7silW8RiEOoLBgAg5JBCL1\", \"Riccardo Muti\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the output graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM.buildGraphNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the current graph to a .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'Graphs/graph_name.txt'\n",
    "NM.writeNetwork(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 2: Graph Features Extraction</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a edge list and build a graph (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 1994 nodes and 13251 edges\n"
     ]
    }
   ],
   "source": [
    "edge_list_path = 'Graphs/kw_2.txt'\n",
    "NM.buildNetworkFromTxt(edge_list_path)\n",
    "graph = NM.Graph_network\n",
    "\n",
    "print(nx.info(graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Extract Features</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popularity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "\n",
      "------------  Start Artist Popularity Calculation ------------\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "[============================================================] 100%\n",
      " Elapsed time : 339.34 s\n"
     ]
    }
   ],
   "source": [
    "popularities = NM.getPopularityScores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "\n",
      "------------  Start Artist Followers Calculation -------------\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "[============================================================] 100%\n",
      " Elapsed time : 270.38 s\n"
     ]
    }
   ],
   "source": [
    "followers = NM.getFollowersNumber()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "\n",
      "------------  Start Number of Albums Calculation -------------\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "[============================================================] 100%\n",
      " Elapsed time : 348.62 s\n"
     ]
    }
   ],
   "source": [
    "num_albums = NM.getNumAlbums()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph nodes features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank = list(nx.pagerank(graph).values())\n",
    "closeness_centralities = list(nx.closeness_centrality(graph).values())\n",
    "degree_centralities = list(nx.degree_centrality(graph).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>CSV creation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Packages and create an instance of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ArtistFeatures import ArtistFeatures\n",
    "AF = ArtistFeatures(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add all the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularities_normalized =  [x / 100.0 for x in popularities]\n",
    "followers_normalized =  [x / max(followers) for x in followers]\n",
    "num_albums_normalized =  [x / max(num_albums) for x in num_albums]\n",
    "\n",
    "AF.add_Feature('Popularities', popularities_normalized)\n",
    "AF.add_Feature('Followers', followers_normalized)\n",
    "AF.add_Feature('Num_Albums', num_albums_normalized) \n",
    "\n",
    "AF.add_Feature('Page_rank',pagerank)\n",
    "AF.add_Feature('Closeness_centralities',closeness_centralities)\n",
    "AF.add_Feature('Degree_centralities',degree_centralities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_csv = 'CSV/kw_2.csv'\n",
    "AF.create_csv(save_path_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 3: Machine Learning</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessay packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset, and divide it into labels Y and data X to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of data :  1994\n",
      "Features :  ['Followers' 'Num_Albums' 'Page_rank' 'Closeness_centralities'\n",
      " 'Degree_centralities']\n"
     ]
    }
   ],
   "source": [
    "csv_path = 'CSV/kw_2.csv'\n",
    "ds = pd.read_csv(csv_path, sep = ',')\n",
    "ds = ds.dropna() \n",
    "\n",
    "Data = ds.values\n",
    "n = Data.shape[0]\n",
    "Y = Data[:n,1]\n",
    "X = Data[:n,2:]\n",
    "feature_names = ds.columns[2:]\n",
    "\n",
    "print(\"Amount of data : \",n)\n",
    "print(\"Features : \",feature_names.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the model into training, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of data for training and deciding parameters: 1329\n",
      "Amount of data for validation : 332\n",
      "Amount of data for test: 333\n"
     ]
    }
   ],
   "source": [
    "n_train = int(2./3.*n)\n",
    "n_val = int((n-n_train)/2.)\n",
    "n_test = n - n_train - n_val\n",
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain_and_val, Xtest, Ytrain_and_val, Ytest = train_test_split(X, Y, test_size=n_test/n)\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(Xtrain_and_val, Ytrain_and_val, test_size=n_val/(n_train+n_val))\n",
    "\n",
    "\n",
    "print(\"Amount of data for training and deciding parameters:\",n_train)\n",
    "print(\"Amount of data for validation :\",n_val)\n",
    "print(\"Amount of data for test:\",n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Linear Regression</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - R^2 on training + validation data : 0.5288\n",
      "1 - R^2 on test data : 0.5979\n"
     ]
    }
   ],
   "source": [
    "LR = linear_model.LinearRegression()\n",
    "\n",
    "LR.fit(Xtrain_and_val, Ytrain_and_val)\n",
    "\n",
    "print(\"1 - R^2 on training + validation data : %.4f\"%(1 - LR.score(Xtrain_and_val,Ytrain_and_val)))\n",
    "print(\"1 - R^2 on test data : %.4f\"%(1 - LR.score(Xtest,Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Decision Trees</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a decision tree and find the optimal depth using grid search with 10-fold cross validaiton procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found :  DecisionTreeRegressor(max_depth=5, min_samples_leaf=3)\n",
      "Best score found : 0.8576\n"
     ]
    }
   ],
   "source": [
    "DTs = DecisionTreeRegressor()\n",
    "param_grid = {\n",
    "    'max_depth': [i for i in range (1,20)],\n",
    "    'min_samples_leaf': [j for j in range (1,5)]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=DTs,\n",
    "                 param_grid= param_grid,\n",
    "                 cv = 10)\n",
    "gs.fit(Xtrain_and_val,Ytrain_and_val)\n",
    "\n",
    "print(\"Best model found : \",gs.best_estimator_)\n",
    "print(\"Best score found : %.4f\"%gs.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the best parameters found, learn a model and print the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - R^2 on training + validation data : 0.1212\n",
      "1 - R^2 on test data : 0.1339\n"
     ]
    }
   ],
   "source": [
    "DT_opt = gs.best_estimator_\n",
    "\n",
    "print(\"1 - R^2 on training + validation data : %.4f\"%(1 - DT_opt.score(Xtrain_and_val,Ytrain_and_val)))\n",
    "print(\"1 - R^2 on test data : %.4f\"%(1 - DT_opt.score(Xtest,Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Decision trees, without number of followers as feature </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modified dataset : creation and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of data :  1994\n",
      "Features for modified dataset :  ['Num_Albums' 'Page_rank' 'Closeness_centralities' 'Degree_centralities']\n"
     ]
    }
   ],
   "source": [
    "######### New dataset ###########\n",
    "Data = ds.values\n",
    "n = Data.shape[0]\n",
    "Y = Data[:n,1]\n",
    "X_mod = Data[:n,3:]\n",
    "feature_names = ds.columns[3:]\n",
    "\n",
    "print(\"Amount of data : \",n)\n",
    "print(\"Features for modified dataset : \",feature_names.values)\n",
    "\n",
    "########  Split into training validation and test #########\n",
    "\n",
    "n_train = int(2./3.*n)\n",
    "n_val = int((n-n_train)/2.)\n",
    "n_test = n - n_train - n_val\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_mod_train_and_val, X_mod_test, Ytrain_and_val, Ytest = train_test_split(X_mod, Y, test_size=n_test/n)\n",
    "X_mod_train, X_mod_val, Ytrain, Yval = train_test_split(Xtrain_and_val, Ytrain_and_val, test_size=n_val/(n_train+n_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees for modified dataset : GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model found :  DecisionTreeRegressor(max_depth=5, min_samples_leaf=3)\n",
      "Best score found : 0.6056\n"
     ]
    }
   ],
   "source": [
    "DT_mod_s = DecisionTreeRegressor()\n",
    "param_grid = {\n",
    "    'max_depth': [i for i in range (1,20)],\n",
    "    'min_samples_leaf': [j for j in range (1,5)]\n",
    "}\n",
    "\n",
    "gs_mod = GridSearchCV(estimator=DT_mod_s,\n",
    "                 param_grid= param_grid,\n",
    "                 cv = 10)\n",
    "gs_mod.fit(X_mod_train_and_val,Ytrain_and_val)\n",
    "\n",
    "print(\"Best model found : \",gs_mod.best_estimator_)\n",
    "print(\"Best score found : %.4f\"%gs_mod.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees : best model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - R^2 on modified training + validation data : 0.3281\n",
      "1 - R^2 on modified test data : 0.3887\n"
     ]
    }
   ],
   "source": [
    "DT_mod_opt = gs_mod.best_estimator_\n",
    "\n",
    "print(\"1 - R^2 on modified training + validation data : %.4f\"%(1 - DT_mod_opt.score(X_mod_train_and_val,Ytrain_and_val)))\n",
    "print(\"1 - R^2 on modified test data : %.4f\"%(1 - DT_mod_opt.score(X_mod_test,Ytest)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4ef9dde2fac0743e98a99859453392d7c3ad2d1585e9d0f04cd34574a900ba4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
