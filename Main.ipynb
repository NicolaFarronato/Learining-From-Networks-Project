{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>LEARNING FROM NETWORK PROJECT</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 1: Network Generation</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages and create an instance of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NetworkManager import NetworkManager\n",
    "NM = NetworkManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the edges list using the <i>featGenerator</i> method  (may take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "--------------------------------------------------------------\n",
      "\n",
      "-------------  Start Artist Featuring Generation -------------\n",
      "\n",
      "--------------------------------------------------------------\n",
      "\n",
      "Riccardo Muti(0) || "
     ]
    }
   ],
   "source": [
    "print(NM.SPOTIFY_MANAGER.artist(\"5K4W6rqBFWDnAN6FQUkS6x\")['popularity'])\n",
    "NM.featGenerator(\"7silW8RiEOoLBgAg5JBCL1\", \"Riccardo Muti\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate and print the output graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM.buildGraphNetwork()\n",
    "NM.plotGraph(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the current graph to a .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = '/Users/nicolafarronato/Documents/GitHub/Learining-From-Networks/Graphs/kw_2.txt'\n",
    "NM.writeNetwork(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 2: Graph Features Extraction</h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a edge list and build a graph (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list_path = '/Users/nicolafarronato/Documents/GitHub/Learining-From-Networks/Graphs/kw_2.txt'\n",
    "NM.buildNetworkFromTxt(edge_list_path)\n",
    "graph = NM.Graph_network\n",
    "#NM.plotGraph(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Extract Features</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popularity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularities = NM.getPopularityScores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers = NM.getFollowersNumber()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_albums = NM.getNumAlbums()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph nodes features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "pagerank = list(nx.pagerank(graph).values())\n",
    "closeness_centralities = list(nx.closeness_centrality(graph).values())\n",
    "#betweenness_centralities = list(nx.betweenness_centrality(graph).values())\n",
    "degree_centralities = list(nx.degree_centrality(graph).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>CSV creation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Packages and create an instance of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ArtistFeatures import ArtistFeatures\n",
    "AF = ArtistFeatures(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add all the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularities_normalized = newList = [x / 100.0 for x in popularities]\n",
    "followers_normalized = newList = [x / max(followers) for x in followers]\n",
    "numalbums_normalized = #da fare...\n",
    "\n",
    "AF.add_Feature('Popularities', popularities_normalized)\n",
    "AF.add_Feature('Followers', followers_normalized)\n",
    "AF.add_Feature('Num_Albums', numalbums_normalized) #da fare...\n",
    "\n",
    "AF.add_Feature('Page_rank',pagerank)\n",
    "AF.add_Feature('Closeness_centralities',closeness_centralities)\n",
    "AF.add_Feature('Degree_centralities',degree_centralities)\n",
    "AF.add_Feature('Betweenness_centralities',betweenness_centralities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path_csv = ''\n",
    "AF.create_csv(save_path_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Part 3: Machine Learning</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "df = pd.read_csv('test.csv', sep = ',')\n",
    "\n",
    "#remove the data samples with missing values (NaN)\n",
    "df = df.dropna() \n",
    "\n",
    "Data = df.values\n",
    "# m = number of input samples\n",
    "m = Data.shape[0]\n",
    "print(\"Amount of data:\",m)\n",
    "Y = Data[:m,1]\n",
    "X = Data[:m,2:]\n",
    "\n",
    "feature_names = df.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train (2/3 of samples), validation (1/6 of samples), and test data (the rest)\n",
    "m_train = int(2./3.*m)\n",
    "m_val = int((m-m_train)/2.)\n",
    "m_test = m - m_train - m_val\n",
    "print(\"Amount of data for training and deciding parameters:\",m_train)\n",
    "print(\"Amount of data for validation (choosing among different models):\",m_val)\n",
    "print(\"Amount of data for test:\",m_test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Xtrain_and_val, Ytrain_and_val is the part of data for training and validation\n",
    "#Xtest, Ytest is the part of data for testing\n",
    "Xtrain_and_val, Xtest, Ytrain_and_val, Ytest = train_test_split(X, Y, test_size=m_test/m)\n",
    "\n",
    "#if you need to consider a specific training and validation split, use\n",
    "#Xtrain, Ytrain for training and Xval, Yval for validation\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(Xtrain_and_val, Ytrain_and_val, test_size=m_val/(m_train+m_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non necessario se i dati sono gi√† normalizzati\n",
    "'''\n",
    "# Data pre-processing\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
    "Xtrain_scaled = scaler.transform(Xtrain)\n",
    "Xtrain_and_val_scaled = scaler.transform(Xtrain_and_val)\n",
    "Xval_scaled = scaler.transform(Xval)\n",
    "Xtest_scaled = scaler.transform(Xtest)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Linear Regression</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "#LR the linear regression model\n",
    "LR = linear_model.LinearRegression()\n",
    "\n",
    "#fit the model on training data\n",
    "LR.fit(Xtrain_and_val_scaled, Ytrain_and_val)\n",
    "\n",
    "print(\"1 - coefficient of determination on training data:\"+str(1 - LR.score(Xtrain_and_val_scaled,Ytrain_and_val)))\n",
    "print(\"1 - coefficient of determination on test data:\"+str(1 - LR.score(Xtest_scaled,Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Neural Networks</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "mlp_cv = MLPRegressor()\n",
    "param_grid = {'hidden_layer_sizes': [i for i in range(1,10)],\n",
    "              'activation': ['relu'],\n",
    "              'solver': ['lbfgs']\n",
    "             }\n",
    "mlp_GS = GridSearchCV(mlp_cv, param_grid=param_grid, cv=5, verbose=True)\n",
    "mlp_GS.fit(Xtrain_and_val_scaled, Ytrain_and_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's print the best model according to grid search\n",
    "print(\"Best model: \",mlp_GS.best_estimator_)\n",
    "#let's print the error 1-R^2 for the best model\n",
    "print(\"Error (1-R^2) of best model: \",1. - mlp_GS.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mlp = MLPRegressor(hidden_layer_sizes=(9,), activation='relu', solver='lbfgs')\n",
    "best_mlp.fit(Xtrain_and_val_scaled,Ytrain_and_val)\n",
    "\n",
    "print(\"Error best model on train and validation: \",1. - best_mlp.score(Xtrain_and_val_scaled,Ytrain_and_val))\n",
    "print(\"Error best model on test data: \",1. - best_mlp.score(Xtest_scaled,Ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Decision Trees</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the proper module\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#define the model\n",
    "DT = DecisionTreeRegressor()\n",
    "\n",
    "#learn the model \n",
    "DT.fit(Xtrain_scaled,Ytrain)\n",
    "\n",
    "#print error on training and on validation\n",
    "print(\"1 - R^2 on training data:\"+str(1 - DT.score(Xtrain_scaled,Ytrain)))\n",
    "print(\"1 - R^2 on valid data:\"+str(1 - DT.score(Xval_scaled,Yval)))\n",
    "print(\"1 - R^2 on test data:\"+str(1 - DT.score(Xtest_scaled,Ytest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees with max depth 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the model\n",
    "DT5 = DecisionTreeRegressor(max_depth=5)\n",
    "\n",
    "#learn the model \n",
    "DT5.fit(Xtrain_scaled,Ytrain)\n",
    "\n",
    "#print error on training and on validation\n",
    "print(\"1 - R^2 on training data:\"+str(1 - DT5.score(Xtrain_scaled,Ytrain)))\n",
    "print(\"1 - R^2 on valid data:\"+str(1 - DT5.score(Xval_scaled,Yval)))\n",
    "print(\"1 - R^2 on test data:\"+str(1 - DT5.score(Xtest_scaled,Ytest)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b4ef9dde2fac0743e98a99859453392d7c3ad2d1585e9d0f04cd34574a900ba4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
